{"cells":[{"metadata":{},"cell_type":"markdown","source":"# I WILL CREDIT https://www.kaggle.com/ajax0564(ANKIT MAURYA) FOR THE TRAINING AND MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\n\nfrom kaggle_datasets import KaggleDatasets","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# v1\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom PIL import Image\n\n# v3\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.utils import shuffle\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.metrics import *\n# v4\n\nACCURACY_LIST = []\nfrom keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom keras.models import Model\n\n\n\n# v6\n# Get reproducible results\nfrom numpy.random import seed\nseed(1)\nimport tensorflow as tf\ntf.random.set_seed(1)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":4,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '/kaggle/input/siim-isic-melanoma-classification/jpeg/'\ntrain_path = data_dir + '/train/'\ntest_path = data_dir + '/test/'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.image import imread","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_ext(fn):\n    return train_path + fn+ '.jpg'\ntrain[\"image_name\"]=train[\"image_name\"].apply(append_ext)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Count of null values in train :\\n{train.isnull().sum()}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" sns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='sex', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='benign_malignant', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# THIS SHOWS THE IMBALANCE IN THE DATASET"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['age_approx']= train['age_approx'].fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = train['age_approx'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute_age(cols):\n    x = cols[0]\n    if(x==0):\n        return mean\n    else:\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['age_approx'] = train[['age_approx']].apply(impute_age, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['anatom_site_general_challenge'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.countplot(x='anatom_site_general_challenge', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['anatom_site_general_challenge']= train['anatom_site_general_challenge'].fillna('torso')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sex']= train['sex'].fillna('male')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = os.listdir(train_path)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam_image = train_path+a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam_img_tensor = imread(sam_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam_img_tensor.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(sam_img_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(train_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image Histograms**\n\n\nAn image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4, 2, figsize=(20, 20))\n\nmalignant_file_paths = train[train['benign_malignant'] == 'malignant']['image_name'].values\nsample_file_paths = malignant_file_paths[:4]\nsample_covid19_file_paths = list(map(lambda x: os.path.join(train_path, x), sample_file_paths))\n\nfor row, file_path in enumerate(sample_file_paths):\n    image = plt.imread(file_path)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label Malignant', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4, 2, figsize=(20, 20))\n\nmalignant_file_paths = train[train['benign_malignant'] == 'benign']['image_name'].values\nsample_file_paths = malignant_file_paths[:4]\nsample_covid19_file_paths = list(map(lambda x: os.path.join(train_path, x), sample_file_paths))\n\nfor row, file_path in enumerate(sample_file_paths):\n    image = plt.imread(file_path)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label Benign', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['diagnosis'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.countplot(x='diagnosis', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('sex', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('patient_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('anatom_site_general_challenge', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('diagnosis', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('age_approx', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('target', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n\n# Configuration\nEPOCHS = 7\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [1024, 1024]\nimSize = 1024","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_path(pre):\n    return np.vectorize(lambda file: os.path.join(GCS_DS_PATH, pre, file))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\ntrain.head(1)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"     image_name  patient_id   sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968  male        45.0                     head/neck   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])# explicit size needed for TPU\n    image = tf.image.resize(image, [imSize,imSize])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        #\"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    #label = tf.cast(example['class'], tf.int32)\n    label = tf.cast(example['target'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['image_name']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nprint('Dataset: {} training images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_TEST_IMAGES))","execution_count":10,"outputs":[{"output_type":"stream","text":"Dataset: 33126 training images, 10982 unlabeled test images\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import Xception","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"METRICS = [\n      BinaryAccuracy(name='accuracy'),\n      Precision(name='precision'),\n      Recall(name='recall'),\n      AUC(name='auc'),\n]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    xception = Xception(\n        input_shape=(*IMAGE_SIZE, 3),\n        weights='imagenet',\n        include_top=False\n    )\n    xception.trainable = True  \n    \n    \n    model = tf.keras.Sequential([\n        xception,\n        L.GlobalAveragePooling2D(),\n        L.Dense(1024),\n        L.ELU(alpha=0.2),\n        L.Dropout(0.4),\n        L.Dense(512),\n        L.LeakyReLU(alpha=0.1),\n        L.Dropout(0.3),\n        L.Dense(256),\n        L.LeakyReLU(alpha=0.1),\n        L.Dropout(0.25),\n        L.Dense(128),\n        L.LeakyReLU(alpha=0.1),\n        L.Dropout(0.2),\n        L.Dense(1, activation='sigmoid')\n    ])\n    model.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        metrics=[METRICS]\n    )","execution_count":13,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 4s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.0001, \n               lr_min=0.000001, lr_rampup_epochs=20, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n# valid_dataset = get_validation_dataset(ordered=False)\ntrain_dataset = get_training_dataset() ","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nmodel.fit(\n    train_dataset, \n    steps_per_epoch=STEPS_PER_EPOCH,\n    epochs=7,\n    callbacks=[lr_schedule])","execution_count":21,"outputs":[{"output_type":"stream","text":"Train for 517 steps\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\nEpoch 1/7\n517/517 [==============================] - 357s 690ms/step - loss: 0.1131 - accuracy: 0.9777 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5899\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 4.95e-05.\nEpoch 2/7\n517/517 [==============================] - 292s 566ms/step - loss: 0.0731 - accuracy: 0.9809 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7553\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 8.9e-05.\nEpoch 3/7\n517/517 [==============================] - 293s 566ms/step - loss: 0.0697 - accuracy: 0.9813 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7956\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0001285.\nEpoch 4/7\n517/517 [==============================] - 293s 567ms/step - loss: 0.0645 - accuracy: 0.9811 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8111\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.000168.\nEpoch 5/7\n517/517 [==============================] - 292s 566ms/step - loss: 0.0643 - accuracy: 0.9810 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8256\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00020749999999999998.\nEpoch 6/7\n517/517 [==============================] - 291s 564ms/step - loss: 0.0615 - accuracy: 0.9812 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8380\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.000247.\nEpoch 7/7\n517/517 [==============================] - 291s 563ms/step - loss: 0.0604 - accuracy: 0.9812 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8473\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f119280f850>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lossess = pd.DataFrame(model.history.history)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lossess.head(7)","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"       loss  accuracy  precision  recall       auc        lr\n0  0.113105  0.977675        0.0     0.0  0.589873  0.000010\n1  0.073105  0.980858        0.0     0.0  0.755335  0.000049\n2  0.069665  0.981271        0.0     0.0  0.795619  0.000089\n3  0.064460  0.981093        0.0     0.0  0.811053  0.000129\n4  0.064268  0.981027        0.0     0.0  0.825629  0.000168\n5  0.061497  0.981250        0.0     0.0  0.838022  0.000207\n6  0.060380  0.981222        0.0     0.0  0.847343  0.000247","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>auc</th>\n      <th>lr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.113105</td>\n      <td>0.977675</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.589873</td>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.073105</td>\n      <td>0.980858</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.755335</td>\n      <td>0.000049</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.069665</td>\n      <td>0.981271</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.795619</td>\n      <td>0.000089</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.064460</td>\n      <td>0.981093</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.811053</td>\n      <td>0.000129</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.064268</td>\n      <td>0.981027</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.825629</td>\n      <td>0.000168</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.061497</td>\n      <td>0.981250</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.838022</td>\n      <td>0.000207</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.060380</td>\n      <td>0.981222</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.847343</td>\n      <td>0.000247</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds,verbose = 1)","execution_count":24,"outputs":[{"output_type":"stream","text":"    172/Unknown - 60s 351ms/step","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')","execution_count":25,"outputs":[{"output_type":"stream","text":"Generating submission.csv file...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\npred_df.head(5)","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"     image_name    target\n0  ISIC_6381819  0.223629\n1  ISIC_5583376  0.009407\n2  ISIC_6408546  0.001220\n3  ISIC_6932354  0.288733\n4  ISIC_8191278  0.137248","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_6381819</td>\n      <td>0.223629</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_5583376</td>\n      <td>0.009407</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_6408546</td>\n      <td>0.001220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_6932354</td>\n      <td>0.288733</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_8191278</td>\n      <td>0.137248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sub['target']\nsub = sub.merge(pred_df, on='image_name')\nsub.to_csv('submission.csv', index=False)\nsub.head(5)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"     image_name    target\n0  ISIC_0052060  0.049339\n1  ISIC_0052349  0.000291\n2  ISIC_0058510  0.001137\n3  ISIC_0073313  0.000009\n4  ISIC_0073502  0.186748","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0.049339</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0.000291</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0.001137</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0.186748</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}